{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import cv2 as cv\n",
    "import albumentations as albu\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as D\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, HorizontalFlip, VerticalFlip, RandomRotate90, Transpose, ShiftScaleRotate, IAAAdditiveGaussianNoise, IAAPerspective,\n",
    "    CLAHE, RandomBrightness, RandomGamma, IAASharpen, Blur, MotionBlur, RandomContrast, HueSaturationValue, VerticalFlip,\n",
    "    RandomRotate90, OneOf, Resize, Rotate, RandomBrightnessContrast, Lambda\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2, ToTensor\n",
    "        \n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = '/home/arti/DL/HuBMAP/Data/256x256/'\n",
    "TEST_DATA_DIR = '/home/arti/DL/HuBMAP/Data/'\n",
    "MODEL_SAVE_DIR = \"/home/arti/DL/HuBMAP/OUTPUTS/models/\"\n",
    "TILE_SIZE = 256\n",
    "REDUCE_RATE = 4\n",
    "SEED = 42\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3676"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_paths, train_mask_paths = [], []\n",
    "for dt in ['train/', 'masks/']:\n",
    "    for item in os.listdir(TRAIN_DATA_DIR+dt):\n",
    "        if dt=='train/':\n",
    "            train_img_paths.append(TRAIN_DATA_DIR+'train/'+item)\n",
    "        elif dt=='masks/':\n",
    "            train_mask_paths.append(TRAIN_DATA_DIR+'masks/'+item)  \n",
    "            \n",
    "paths = list(zip(train_img_paths, train_mask_paths))\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/home/arti/DL/HuBMAP/Data/256x256/train/095bf7a1f_628.png',\n",
       "  '/home/arti/DL/HuBMAP/Data/256x256/masks/095bf7a1f_628.png')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = cv.imread(self.paths[i][0])\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        mask = cv.imread(self.paths[i][1], 0)  # 0=cv2.IMREAD_GRAYSCALE, np.array of 0 and 1. (256,256)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask) # image np(256,256,3) -> tensor(3,256,256)\n",
    "            image, mask = augmented['image'], augmented['mask']\n",
    "            mask = mask.unsqueeze(0) # (256,256) -> (1, 256, 256)\n",
    "        return image, mask\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, paths, transform=None):\n",
    "        self.paths = paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv.imread(self.paths[i][0])\n",
    "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            RandomRotate90(p=0.5),\n",
    "            Transpose(p=0.5),\n",
    "\n",
    "            ShiftScaleRotate(scale_limit=0.2, rotate_limit=0, shift_limit=0.2, p=0.2, border_mode=0),\n",
    "\n",
    "            IAAAdditiveGaussianNoise(p=0.2),\n",
    "            IAAPerspective(p=0.5),\n",
    "\n",
    "            OneOf([\n",
    "                    CLAHE(p=1),\n",
    "                    RandomBrightness(p=1),\n",
    "                    RandomGamma(p=1),\n",
    "                ], p=0.9,\n",
    "            ),\n",
    "\n",
    "            OneOf([\n",
    "                IAASharpen(p=1),\n",
    "                Blur(blur_limit=3, p=1),\n",
    "                MotionBlur(blur_limit=3, p=1),\n",
    "            ], p=0.9,\n",
    "            ),\n",
    "\n",
    "            OneOf([   \n",
    "                RandomContrast(p=1),\n",
    "                HueSaturationValue(p=1),],  p=0.9,\n",
    "            ),\n",
    "            Compose([\n",
    "                VerticalFlip(p=0.5),              \n",
    "                RandomRotate90(p=0.5)]\n",
    "            ),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),  #ToTensor(num_classes=2),\n",
    "        ])    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(256,256),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of train samples: 2940\n",
      "Amount of val samples: 736\n"
     ]
    }
   ],
   "source": [
    "train_paths, val_paths = train_test_split(paths, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "print(\"Amount of train samples:\", len(train_paths))\n",
    "print(\"Amount of val samples:\", len(val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(encoder_name='se_resnext50_32x4d', encoder_weights='imagenet', activation='sigmoid')\n",
    "#model = smp.FPN(encoder,encoder_weights=encoder_weights)\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_paths, transform=get_transforms(data='train'),)\n",
    "valid_dataset = TrainDataset(val_paths, transform=get_transforms(data='valid'),)\n",
    "\n",
    "train_loader = D.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = D.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1.0\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_scores, val_scores = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 184/184 [01:11<00:00,  2.58it/s, dice_loss - 0.8323, iou_score - 0.2422]\n",
      "valid: 100%|██████████| 46/46 [00:04<00:00, 10.62it/s, dice_loss - 0.6948, iou_score - 0.599] \n",
      "\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    \n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    \n",
    "    train_losses.append(train_logs['dice_loss'])\n",
    "    val_losses.append(valid_logs['dice_loss'])\n",
    "    train_scores.append(train_logs['iou_score'])\n",
    "    val_scores.append(valid_logs['iou_score'])\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    if best_loss > valid_logs['dice_loss']:\n",
    "        best_loss = valid_logs['dice_loss']\n",
    "        torch.save(model, os.path.join(MODEL_SAVE_DIR, 'best_model_sub.pth'))\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(val_losses, label='val loss')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_scores, label='train score')\n",
    "plt.plot(val_scores, label='val score')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
